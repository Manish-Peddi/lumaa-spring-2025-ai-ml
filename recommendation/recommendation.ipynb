{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82173bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89254d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb067b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\") #file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b53dbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd45c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184bcdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data['Movie Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdbc23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description'] = data['Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40db8e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d3fc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The provided task is to process the text data and formulate recommendation function :\n",
    "\n",
    "df.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a69bffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Importing natural language toolkit functions to process text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4f8d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [word_tokenize(text) for text in df['description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f674f69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ac55ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reducing the tokens into lower case letters :  (normalizing)\n",
    "\n",
    "\n",
    "normalized_tokens = [[current.lower() for current in token] for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34edce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now as the tokens are normalized, we can remove the english stop words from the text. \n",
    "\n",
    "stops = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eccbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering the text normalized tokens to remove stop words on \"stops\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5bf140",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_tokens = [[word for word in text] for text in tokens if text not in stops]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2085620",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9a2335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the stop words are filtered out and filtered token list contains only non stop word lists.\n",
    "\n",
    "\n",
    "# Punctuations should also be removed from the text. \n",
    "\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf9c1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(words):\n",
    "    return [word for word in words if word.isalpha() and word not in string.punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d2ace9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = [remove_punctuation(word) for word in filtered_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa7303a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c201b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the data is tokenized and vectorization can be done. \n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity   # for similarity index and recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4e650e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['filtered_description'] = filtered\n",
    "df['filtered_description'] = df['filtered_description'].apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76608301",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95501aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorization\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(df[\"filtered_description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc83c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af68edd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need to prepare a recommendation function that will take the input of description string from the user\n",
    "# recommend similar movies to the user. \n",
    "\n",
    "\n",
    "\n",
    "# 1. Take input -> pre-process and convert -> calculate similarity -> Recommend top 5.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f311fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(input_string, df=df, vectorizer=vectorizer, tfidf_matrix=tfidf_matrix):\n",
    "\n",
    "    # pre-processing the input text (same functions as done before)\n",
    "    tokens = word_tokenize(input_string)  # tokenizing\n",
    "    normalized_tokens = [current.lower() for current in tokens]  # Normalizing (to lower case)\n",
    "    filtered_tokens = [word for word in normalized_tokens if word not in stops] # removing stop words\n",
    "    filtered_input_tokens = remove_punctuation(filtered_tokens)\n",
    "    filtered_string = \" \".join(filtered_input_tokens)\n",
    "    \n",
    "    # vectorizing input \n",
    "    \n",
    "    input_vector = vectorizer.transform([filtered_string])\n",
    "    \n",
    "    # calculating similarity between input and data vectors\n",
    "    \n",
    "    cosine_sim = cosine_similarity(input_vector, tfidf_matrix).flatten()\n",
    "    \n",
    "    # retreiving and returning top 5 movies\n",
    "    \n",
    "    sim_scores = sorted(list(enumerate(cosine_sim)), key=lambda x: x[1], reverse=True)\n",
    "    top_movies = [df[\"Movie Name\"].iloc[i[0]] for i in sim_scores[:5]]\n",
    "    \n",
    "    return top_movies\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80f6ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage of the function and similarity model :: \n",
    "\n",
    "\n",
    "movie_description = df['description'][np.random.randint(0, len(df))]\n",
    "print (movie_description)\n",
    "print()\n",
    "print(\"As per the description, the top 5 recommended picks are \") \n",
    "recommend(movie_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1272f96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
